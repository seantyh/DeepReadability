{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import keras\n",
    "import preproc\n",
    "from importlib import reload\n",
    "import train_utils\n",
    "import keras\n",
    "import preproc\n",
    "import train_utils\n",
    "import setup_model\n",
    "\n",
    "DATA_DIR = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 2500\n",
    "data, labels = pickle.load(open(DATA_DIR + \"/train_data.pyObj\", \"rb\"))\n",
    "labels = labels - 1\n",
    "freq_vec = data[\"freq\"]\n",
    "stroke_vec = data[\"stroke\"]\n",
    "\n",
    "np.random.seed(125655)\n",
    "rand_idx = np.random.permutation(range(len(labels)))\n",
    "train_idx = rand_idx[:int(len(rand_idx) * 0.6)]\n",
    "cv_idx = rand_idx[int(len(rand_idx) * 0.6):int(len(rand_idx) * 0.2)]\n",
    "test_idx = rand_idx[int(len(rand_idx) * 0.8):]\n",
    "text_mat = preproc.preproc_text_vec(data[\"text\"], VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "USE_SAVED = True\n",
    "if USE_SAVED:\n",
    "    model = keras.models.load_model(\"model.h5\")\n",
    "else:\n",
    "    model = setup_model.setup_model(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Attempt to create an image of a blank graph to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pydot raises a generic Exception here, so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-18020722eab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pydot raises a generic Exception here, so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     21\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 784 samples\n",
      " --- Epoch 0 --- \n",
      "[   0] cost: 1.35231, accuracy: 1.00\n",
      "[   1] cost: 1.37075, accuracy: 1.00\n",
      "[   2] cost: 1.58928, accuracy: 0.67\n",
      " --- Epoch 1 --- \n",
      "[   0] cost: 1.48184, accuracy: 0.80\n",
      "[   1] cost: 1.44392, accuracy: 0.83\n",
      "[   2] cost: 1.51751, accuracy: 0.71\n",
      " --- Epoch 2 --- \n",
      "[   0] cost: 1.42903, accuracy: 0.78\n",
      "[   1] cost: 1.37151, accuracy: 0.80\n",
      "[   2] cost: 1.43588, accuracy: 0.70\n",
      " --- Epoch 3 --- \n",
      "[   0] cost: 1.20922, accuracy: 0.80\n",
      "[   1] cost: 1.09501, accuracy: 0.80\n",
      "[   2] cost: 1.19584, accuracy: 0.70\n",
      " --- Epoch 4 --- \n",
      "[   0] cost: 0.949924, accuracy: 0.80\n",
      "[   1] cost: 0.852173, accuracy: 0.80\n",
      "[   2] cost: 0.937655, accuracy: 0.70\n",
      " --- Epoch 5 --- \n",
      "[   0] cost: 0.690789, accuracy: 0.80\n",
      "[   1] cost: 0.626508, accuracy: 0.80\n",
      "[   2] cost: 0.772273, accuracy: 0.70\n",
      " --- Epoch 6 --- \n",
      "[   0] cost: 0.544295, accuracy: 0.80\n",
      "[   1] cost: 0.506109, accuracy: 0.80\n",
      "[   2] cost: 0.65539, accuracy: 0.70\n",
      " --- Epoch 7 --- \n",
      "[   0] cost: 0.458682, accuracy: 0.80\n",
      "[   1] cost: 0.443126, accuracy: 0.80\n",
      "[   2] cost: 0.598679, accuracy: 0.70\n",
      " --- Epoch 8 --- \n",
      "[   0] cost: 0.412607, accuracy: 0.80\n",
      "[   1] cost: 0.404979, accuracy: 0.80\n",
      "[   2] cost: 0.559984, accuracy: 0.70\n",
      " --- Epoch 9 --- \n",
      "[   0] cost: 0.381023, accuracy: 0.80\n",
      "[   1] cost: 0.376728, accuracy: 0.80\n",
      "[   2] cost: 0.528007, accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 10\n",
    "cost_vec = []\n",
    "acc_vec = []\n",
    "print(\"Training data: %d samples\" % len(train_idx))\n",
    "\n",
    "for epoch_i in range(EPOCH):\n",
    "    print(\" --- Epoch {} --- \".format(epoch_i))\n",
    "    counter = 0\n",
    "\n",
    "    for sample_idx in train_idx:\n",
    "        sample = text_mat[sample_idx]\n",
    "        label = labels[sample_idx]\n",
    "        freq = freq_vec[sample_idx]\n",
    "        stroke = stroke_vec[sample_idx]\n",
    "        freq = freq / np.sum(freq)\n",
    "        stroke = stroke/np.sum(stroke)\n",
    "        ret = model.train_on_batch(\n",
    "                [np.array([sample]), np.array([freq]), np.array([stroke])], \n",
    "                keras.utils.to_categorical(label, 6))\n",
    "        cost_vec.append(ret[0])\n",
    "        acc_vec.append(ret[1])\n",
    "\n",
    "        global_iter = epoch_i * len(train_idx) + counter        \n",
    "\n",
    "        mv_cost = np.mean(cost_vec[-100:])\n",
    "        mv_acc = np.mean(acc_vec[-100:])\n",
    "        if (global_iter + 1) % 100 == 0:\n",
    "            train_utils.write_log(tb_callback, global_iter, \n",
    "                    [\"loss\", \"accuracy\"], [mv_cost, mv_acc])\n",
    "\n",
    "        if (global_iter + 1) % 500 == 0:                        \n",
    "            print(\"validating model...\")\n",
    "            val_loss, val_acc = train_utils.test_model(\n",
    "                model, test_idx, data, labels, VOCAB_SIZE)\n",
    "            print(\"Validation: loss: {:f}, acc: {:.2f}\".format(val_loss, val_acc))\n",
    "            train_utils.write_log(tb_callback, global_iter, \n",
    "                    [\"val_loss\", \"val_accuracy\"], [val_loss, val_acc])    \n",
    "\n",
    "        # if counter >= 3:\n",
    "        #     break   \n",
    "        print(\"[% 4d] cost: %s, accuracy: %.2f\" % (counter, mv_cost, mv_acc))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(freq_vec[sample_idx]).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: loss: 2.675456, acc: 0.42\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = train_utils.test_model(\n",
    "                    model, test_idx, data, labels, VOCAB_SIZE)\n",
    "print(\"Validation: loss: {:f}, acc: {:.2f}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train_utils)\n",
    "ypred = train_utils.predict_model(model, test_idx, data, VOCAB_SIZE)\n",
    "yans = labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  7  2  1  0  0]\n",
      " [17 16 14  3  0  0]\n",
      " [ 2  5 15 21  6  1]\n",
      " [ 0  1  5 29 16  6]\n",
      " [ 0  1  2 12 17  3]\n",
      " [ 0  0  0  8 18 15]]\n",
      "Accuracy: 0.4237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M6 = confusion_matrix(yans, ypred)\n",
    "acc6 = np.sum(np.diag(M6)) / np.sum(M6)\n",
    "print(M6)\n",
    "print(\"Accuracy: %.4f\" % acc6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59 20  0]\n",
      " [ 8 70 29]\n",
      " [ 1 22 53]]\n",
      "Accuracy: 0.6947\n"
     ]
    }
   ],
   "source": [
    "M3 = confusion_matrix(np.int32(yans / 2), np.int32(ypred / 2))\n",
    "acc3 = np.sum(np.diag(M3)) / np.sum(M3)\n",
    "print(M3)\n",
    "print(\"Accuracy: %.4f\" % acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decoder\n",
    "reload(decoder)\n",
    "dec = decoder.Decoder(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "DOC_TEXT=\"\"\"\n",
    "觀自在菩薩。行深般若波羅蜜多時。照見五蘊皆空。度一切苦厄。舍利子。色不異空。空不異色。色即是空。空即是色。受想行識。亦復如是。舍利子。是諸法空相。不生不滅。不垢不淨。不增不減。是故空中無色。無受想行識。無眼耳鼻舌身意。無色聲香味觸法。無眼界。乃至無意識界。無無明。亦無無明盡。乃至無老死。亦無老死盡。無苦集滅道。無智亦無得。以無所得故。菩提薩埵。依般若波羅蜜多故。心無罣礙。無罣礙故。無有恐怖。遠離顛倒夢想。究竟涅槃。三世諸佛。依般若波羅蜜多故。得阿耨多羅三藐三菩提。故知般若波羅蜜多。是大神咒。是大明咒。是無上咒。是無等等咒。能除一切苦。真實不虛。故說般若波羅蜜多咒。即說咒曰。\n",
    "揭諦揭諦　波羅揭諦　波羅僧揭諦　菩提薩婆訶\n",
    "\"\"\"\n",
    "grade = dec.predict_text(DOC_TEXT)\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "DOC_TEXT=\"\"\"\n",
    "既然你誠心誠意的發問了 \n",
    "我們就大發慈悲的告訴你 \n",
    "為了防止世界被破壞 \n",
    "為了守護世界的和平 \n",
    "貫徹愛與真實的邪惡 \n",
    "可愛又迷人的反派角色 \n",
    "武藏！ \n",
    "小次郎！ \n",
    "我們是穿梭在銀河中的火箭隊 \n",
    "白洞、白色的明天正等著我們 \n",
    "就是這樣喵！ \n",
    "\"\"\"\n",
    "grade = dec.predict_text(DOC_TEXT)\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
